{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Copying crawl_lu_temple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "form bs4 import BeautifulSoup\n",
    "import urllib\n",
    "from urllib import request\n",
    "import re\n",
    "import csv\n",
    "import os.path\n",
    "import time\n",
    "import datetime\n",
    "import codecs\n",
    "\n",
    "import http.client\n",
    "http.client.HTTPConnection._http_vsn = 10\n",
    "http.client.HTTPConnection._http_vsn_str = 'HTTP/1.0'\n",
    "\n",
    "\n",
    "\n",
    "def readfromweb(year, quarter):\n",
    "    \n",
    "    data = urllib.request.urlopen(\"https://www.sec.gov/Archives/edgar/full-index/%s/QTR%s.company.idx\" %(year, quarter))\n",
    "    datastring = data.read()\n",
    "                                  \n",
    "    return datastring\n",
    "                                  \n",
    "def readfromfile(year, quarter):\n",
    "    with open(\"%_%s.idx\" %(year, quarter), \"r\") as f:\n",
    "        return f.read()\n",
    "    \n",
    "def writecsv(l, filename):\n",
    "    \n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csvfiel:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(l)\n",
    "        \n",
    "def readindex(year, quarter):\n",
    "    print(year, quarter)\n",
    "    \n",
    "    if not os.path.exists(\"%s_%s.idx\" %(year, quarter)):\n",
    "        with open(\"%s_%s.idx\" %(year, quarter)< \"wb\") as f:\n",
    "            f.write(readfromweb(year, quarter))\n",
    "            \n",
    "    print(\"readfromweb complete\")\n",
    "    \n",
    "    data = readfromfile(year, quarter)\n",
    "    \n",
    "    print(\"readfromfile complete\")\n",
    "    \n",
    "    datalines = data.split(\"Wn\")\n",
    "    print(len(datalines))\n",
    "    print(datalines[0:10])\n",
    "    assert re.match(\"^-+$\", datalines[9])\n",
    "    datakeep = []\n",
    "    datareject = []\n",
    "    i = 0\n",
    "    for line in datalines[10:]:\n",
    "        companyName = line[0:62].strip()\n",
    "        formTypes = line[74:86].strip()\n",
    "        Clk = line[74:86].\n",
    "        date = line[86:98]. strip()\n",
    "        URL_10k = line[98:].strip()\n",
    "        if re.search('10[v-]?[kk]', formTypes) and not re.search('NT', formTypes):\n",
    "            datakeep.append([companyName, formTypes, CLK, data, URL_10K])\n",
    "        else:\n",
    "            datareject.append([companyName, formTypes, ClK, data, URL_10K])\n",
    "            \n",
    "        I=I+1\n",
    "## If I==100:\n",
    "##     ##print(datakeep)\n",
    "##     break\n",
    "    writecsv(datakeep, \"%s_%s.csv\" %(year, quarter))\n",
    "    writecsv(datareject, \"s_%s_rej.csv\" %(year, quarter))\n",
    "    \n",
    "\n",
    "def readforms(year, quarter):\n",
    "    \n",
    "##    global alternate_exists\n",
    "##    print(mode)\n",
    "\n",
    "    with open(\"%s_%s.csv\" %(year, quarter), \"r\") as URLfile:\n",
    "        datareader = csv.reader(URLfile)\n",
    "        name = []\n",
    "        cik = []\n",
    "        date = []\n",
    "        URLs = []\n",
    "        forms = []\n",
    "        for row in datareader:\n",
    "            URLs.append(row[4])\n",
    "            forms.append(row[1])\n",
    "            name.append(row[0])\n",
    "            cik.append(row[2])\n",
    "            date.append(row[3])\n",
    "    datamax=0\n",
    "    \n",
    "    problems = []\n",
    "    tpeypetoyr=[]\n",
    "    rowtowrite.append([\"CLK\",\n",
    "                       \"Name\",\n",
    "                       \"Form\",\n",
    "                       \"Filing date\",\n",
    "                       \"Filing year\",\n",
    "                       \"Filing quarter\",\n",
    "                       \"URL of form\",\n",
    "                       \"public float 1\",\n",
    "                       \"public float 2\",\n",
    "                       \"extract\",\n",
    "                       \"point of public float\",\n",
    "                       \"position of something...\"\n",
    "                       \"checkbox extract\",\n",
    "                       \"LAF\", \"AF\", \"NAF\", \"SRC\",\n",
    "                       \"LAF2\", \"AF2\", \"NAF2\", \"SRC2\",\n",
    "                       \"Filing status\",\n",
    "                       \"FYenddate\",\n",
    "                       \"FY year\",\n",
    "                       \"Filing status, alternate\",\n",
    "                       \"Accelerated filer status, pre-2005\",\n",
    "                       \"Filing status 2\"])\n",
    "    parser_set = [\"html.parser\", \"html5lib\", \"lxml\"]\n",
    "    checkboxtestset = [\"whether the registrant is a large accelerated\",\n",
    "                       \"whether registrant is a large accelerated\",\n",
    "                       \"if the registrant is a large accelerated\",\n",
    "                       \"if the company is a large accelerated\",\n",
    "                       \"if company is a large accelerated\",\n",
    "                       \"if registrant is a large accelerated\",\n",
    "                       \"is one of the following: (1) large accelerated\",\n",
    "                       \"whether each registrnat is a large accelerated\",\n",
    "                       \"if each registrant is a large accelerated\"]\n",
    "    accfilchecks = [\"the agg\",\n",
    "                    \"state\",\n",
    "                    \"the appro\",\n",
    "                    \" at \",\n",
    "                    \"based\",\n",
    "                    \"indicate\",\n",
    "                    \" on \",\n",
    "                    \"(1)\",\n",
    "                    \"aggregate\",\n",
    "                    \" 1 \",\n",
    "                    \"-1-\",\n",
    "                    \".---\",\n",
    "                    \"as the reg\",\n",
    "                    \"table\",\n",
    "                    \"the common\",\n",
    "                    \"the registrant\",\n",
    "                    \"the number\",\n",
    "                    \"the issuer\",\n",
    "                    \"explanatory\",\n",
    "                    \"-at\",\n",
    "                    \"*this\",\n",
    "                    \"* this\",\n",
    "                    \"the market\",\n",
    "                    \"market\",\n",
    "                    \"issuer\",\n",
    "                    \"registrant does\",\n",
    "                    \"non-aff\",\n",
    "                    \"for the year\",\n",
    "                    \"cover\",\n",
    "                    \"form 10\",\n",
    "                    \"registrant had\",\n",
    "                    \"all of\",\n",
    "                    \"part i item\",\n",
    "                    \"there is\",\n",
    "                    \"there were\",\n",
    "                    \"see page\",\n",
    "                    \"this doc\",\n",
    "                    \"applicable\",\n",
    "                    \"the company\",\n",
    "                    \"upon\",\n",
    "                    \"-----\",\n",
    "                    \"the closing\",\n",
    "                    \"number of\",\n",
    "                    \"shares of\",\n",
    "                    \"wholly\",\n",
    "                    \"while\",\n",
    "                    \"-on\",\n",
    "                    \"no voting\",\n",
    "                    \"this annual\",\n",
    "                    \"none of\",\n",
    "                    \"page\",\n",
    "                    \"all outstanding\",\n",
    "                    \"all common\",\n",
    "                    \"registrant has\",\n",
    "                    \"the members\",\n",
    "                    \"portions of\",\n",
    "                    \"the libited\",\n",
    "                    \"because\",\n",
    "                    \"[cover\",\n",
    "                    \"the [\",\n",
    "                    \"common stock\",\n",
    "                    \"revenues\",\n",
    "                    \"(form\",\n",
    "                    \"nbsp\"]\n",
    "    chbxts = [\"(check one):\",\n",
    "              \"(check one).\",\n",
    "              \"(check one)\",\n",
    "              \"12b-2).:,\n",
    "              \"12b-2.\",\n",
    "              \"exchange act.\",\n",
    "              \"exchange act:\",\n",
    "              \"exchange act).\",\n",
    "              \"exchange act):\",\n",
    "              \"exhange act)\",\n",
    "              \"exchange act .\",\n",
    "              \"of the act).\",\n",
    "              \"of the act.\",\n",
    "              \"or a smaller reporting company.\",\n",
    "              \"or a smaller reporting company:\",\n",
    "              \"or a non-accelerated filer.\",\n",
    "              \"or a non-accelerated filler:\",\n",
    "              \"of 1934:\"\n",
    "              \"of 1934).\",\n",
    "              \"of 1934.\",\n",
    "              \"of 1934)\",\n",
    "              \"of 1934\",\n",
    "              \"of the exchange act\",\n",
    "              \"or a smaller reporting company\",\n",
    "              \"or a non-accerlerated filer\",\n",
    "              \"12b-2\",\n",
    "              \"12b\"]\n",
    "    \n",
    "##    print(\"rowwritten\")\n",
    "##    URLs = [\"edgar/data/702259/0000950148-03-000640.txt*]\n",
    "\n",
    "    for i in ramge(URLs):  ## set to range(1000) when running abbreviated\n",
    "##        if i<5195:\n",
    "##             continue\n",
    "        largest = \"none\"\n",
    "        trymarker=0\n",
    "##         if quarter == 1:\n",
    "##             continue\n",
    "##         if i<5205:\n",
    "##             continue\n",
    "##         if i>80:\n",
    "##              continue\n",
    "##         print(i)\n",
    "        filingstatus = \"\"\n",
    "        filingstatus2 = \"\"\n",
    "        FYenddate = \"\"\n",
    "        FY_year = \"\"\n",
    "        pointofPF = 0\n",
    "        FYenddatechecks = [\" or \",\n",
    "                           \" l\",\n",
    "                           \"-\",\n",
    "                           \"transition report\",\n",
    "                           \" [\",\n",
    "                           \" _\",\n",
    "                           \".\",\n",
    "                           \" file\"\",\n",
    "                           \" commission\",\n",
    "                           \" restated\"]\n",
    "        mktval=\"blank market val\"\n",
    "        largest = \"blank largest val\"\n",
    "        bartsection = \"\"\n",
    "        \n",
    "        \n",
    "        LAF2 = \"\"\n",
    "##        print(\"inside for loop\")\n",
    "##        print(URLs[i])\n",
    "        try:\n",
    "            data = urllib.request.urlopen(\"http://www.sec.gov/Archives/%s\" %(URLs[i]), timeout=10).read(100000)\n",
    "##             print(type(data))\n",
    "##        print(\"URL opend\")\n",
    "        ##souptext = str(data)\n",
    "        except urllib.error.URLError:\n",
    "            data = \"\"\n",
    "            rowtowrite.append([cik[i], name[i], forms[i], year, quarter, \"http://www.sec.gov/Archives/%s\" %(URLs[i]), \"timeout error\"])\n",
    "            continue\n",
    "        except Keyboardinterrupt:\n",
    "            raise Keyboardinterrupt\n",
    "        except:\n",
    "            rowtowrite.append([cik[i], name[i], forms[i], year, quarter, \"http://www.sec.gov/Archives?%s\" %(URLs[i]), \"other URL reading error\"])\n",
    "            continue\n",
    "        try:\n",
    "            souptext = data.decode('utf-8')\n",
    "##             taboon = souptext.find(\"TABLE OF CONTENTS\")\n",
    "##             if taboon !=-1:\n",
    "##              souptext = souptext[0:taboon+1]\n",
    "            docref = souptext.find(\"DOCUMENTS INCORPORATED BY REFERENCE\")\n",
    "            if docref !=-1:\n",
    "                souptext = souptext[0:docref+1]\n",
    "            souptextup = souptext.upper()\n",
    "            \n",
    "            pl = souptext.find(\"PART l ITEM 1\")\n",
    "            if p1 !=-1:\n",
    "                souptext = souptext[0:p1]\n",
    "            docref = souptextup.find(\"DOCUMENTS INCORPORATED BY REFERENCE\")\n",
    "            if docref != -1:\n",
    "                souptext = souptext[0:docref+1]\n",
    "##             jpegloo = souptextup.find(\".JPG\")\n",
    "##             if jpegloc !=-1:\n",
    "##                 souptext = souptext[0:jpegloc+1]\n",
    "##             else:\n",
    "####                  print(i)\n",
    "####                  print(\"it wasn't found!\")\n",
    "##                  if len(souptext)>50000:\n",
    "##                       souptext = souptext[0:49999]\n",
    "            souptextforparse = souptext\n",
    "            for parsing in parser_set:\n",
    "##                 print(parsing)\n",
    "            try:\n",
    "                soup = BeautifulSoup(souptextforparse, parsing)\n",
    "                break\n",
    "    ##         print(\"souped\")\n",
    "            except RuntimeWarning:\n",
    "                print(\"RUNTIME WARNING EXCEPTION!!!!!!!!!!!1\")\n",
    "                if parsing == \"html5lib\":\n",
    "                    souptext = \" \"\n",
    "                    soup = \" \"\n",
    "##               print(URLs[i])\n",
    "                problems.append([year, quarter, URLs[i], \"runtime warning exception\"])\n",
    "                continue\n",
    "            except Keyboardinterrupt:\n",
    "                raise Keyboardinterrupt\n",
    "            except:\n",
    "                print(\"EXCEPTION!!!!!!!!!!!!!\")\n",
    "                if parsing == \"html5lib\":\n",
    "                    souptext = \" \"\n",
    "                    soup = \" \"\n",
    "##                print(URLs[i])\n",
    "                problems.append([year, quarter, URLs[i], \"parser exception 1\"])\n",
    "                continue\n",
    "##           print(len(souptext))\n",
    "##           data.close()\n",
    "\n",
    "\n",
    "##           if i==16:\n",
    "##                print(souptext)\n",
    "            souptext = soup.get_text(\"\", strip=True)\n",
    "    \n",
    "##           if i==18:\n",
    "##               print(souptext)\n",
    "\n",
    "            souptext = souptext.replace(\"\\\\n\", \" \")\n",
    "            souptext = souptext.replace(\"\\n', \" \")\n",
    "            souptext = souptext.replace(\"Series\", \" SERIES\")\n",
    "            souptext = souptext.replace(\"$ \", \"$\")\n",
    "            souptext = souptext.replace(\"$_\", \"$0 \")\n",
    "            souptext = souptext.replace(\" \", \" \")\n",
    "            souptext = souptext.replace(\".(\", \". (\")\n",
    "            souptext = souptext.replace(u'\\xa0', u' ')\n",
    "            souptext = souptext.replace(\"non &#150;acc\", \"non-acc\")\n",
    "            souptext = souptext.replace(\"$-0-\", \"$0\")\n",
    "            souptext = souptext.replace(\"nonaffiliats\", \"non-acc\")\n",
    "            souptext = souptext.replace(\"nonaccelerated\", \"non-affiliatex\")\n",
    "            souptext = souptext.replace(\"Non accelerated\", \"Non-accelerated\")\n",
    "            souptext = souptext.replace(\"Non Accelerated\", \"Non-accelerated\")\n",
    "            souptext = souptext.replace(\"non accelerated\", \"Non-accelerated\")\n",
    "            souptext = souptext.replace(\"Nonaccelerated\", \"Non-accelerated\")\n",
    "            souptext = souptext.replace(\"12(b)-2\", \"12b-2\")\n",
    "            souptext = souptext.replace(\"12(b)2\", \"12b-2\")\n",
    "            souptext = souptext.replace(\"12-b2\", \"12b-2\")\n",
    "            souptext = souptext.replace(\"12-b-2\", \"12b-2\")\n",
    "            souptext = souptext.replace(\"filler\", \"filer\")\n",
    "            souptext = souptext.replace(\"$USD\", \"$\")\n",
    "            souptext = souptext.replace(\"USD\", \"$\")\n",
    "            souptext = souptext.replace(\"$US\", \"$\")\n",
    "            souptext = souptext.replace(\"$$\", \"$\")\n",
    "            souptext = souptext.replace(\"$\" , \"$\")\n",
    "            souptext = souptext.replace(\"&nbsp;\", \" \")\n",
    "            souptext = \" \".join(souptext.split())\n",
    "            \n",
    "            souptextlower = souptext.lower()\n",
    "##             if i==16:\n",
    "##                 print(souptext)\n",
    "                                        \n",
    "                                        \n",
    "            poimtofPF=souptextlower.find(\"non-affiliates\")\n",
    "                                        \n",
    "            donotcheckfind = souptextlower.find(\"(do not check\", souptextlower.find(\"accelerated\"))\n",
    "            if donotcheckfind<0:\n",
    "                 donotcheckfind = souptextlower.find(\"do not mark\", souptextlower.find(\"accelerated\"))\n",
    "            donotcheckend = souptextlower.find(\")\", donotcheckfind)\n",
    "            if donotcheckfind>0:\n",
    "                souptext = souptext.replace(souptext[donotcheckfind:donotcheckend+1], \"\")\n",
    "            souptext = \" \".join(souptext.split())\n",
    "                                        \n",
    "                                        \n",
    "##             taboon = souptext.find(\"TABLE OF CONTENTS\")\n",
    "##             if taboon != -1:\n",
    "##                  souptext = souptext[0:taboon+1]\n",
    "            p1 = souptext.find(\"PART I ITEM 1\")\n",
    "            if p1 != -1:\n",
    "                souptext = souptext[0:p1]\n",
    "            docref = souptext.find(\"DOCUMENTS INCORPORATED BY RERERENCE\")\n",
    "            if docref != -1:\n",
    "                 souptext = souptext[0:docref+1]\n",
    "            souptextup = souptext.upper()\n",
    "            docref = souptextup.find(\"DOCUMENTS INCORPARATED BY REFERENCE\")\n",
    "            if docref !=-1:\n",
    "                souptext = souuptext[0:docref+1]\n",
    "                                        \n",
    "            souptext = \" \".join(souptext.split())\n",
    "                                   \n",
    "##            print(\"soup replacements amde\")\n",
    "                                        \n",
    "            souptext_noascii = removeNonAscii(souptext)\n",
    "            souptext_noascii = souptext_noascii.replace(\"non- aff\", \"non-aff\")\n",
    "            souptext_noascii = souptext_noascii.replace(\"non aff\", \"non-aff\")\n",
    "            souptext_noascii = \" \".join(souptext_noascii.split())\n",
    "            \n",
    "            lct =  (souptext_noascill.find(\"by non-affiliates\"))\n",
    "##             if lot != -1:\n",
    "##                  break\n",
    "            if lct == -1:\n",
    "                 lct = souptext_noascii.find(\"by non-affiliates\")\n",
    "            pos = souptext_noascii.find(\"$\", lct)\n",
    "##            pointofPF = pos\n",
    "            souptextlower = souptext_noascii.lower()\n",
    "            souptext2 = souptext\n",
    "            souptext = souptext_noascii\n",
    "                                        \n",
    "##             if i ==18:\n",
    "##                  print(souptext)\n",
    "            \n",
    "            if lct==-1:\n",
    "                if souptextlower.find(\"no public market for the registrant' s common stock\")>0:\n",
    "                    mktval = \"no public market\"\n",
    "                elif souptextlower.find(\"no definition available\". lct-200, lct+400)>0:\n",
    "                    mktval = \"no definition avilable\"\n",
    "                elif souptextlower.find9\"because the registrant is a wholly-owned subsidiary\")>0:\n",
    "                    mktval = \"wholly owned subsidiary\"\n",
    "                elif souptextlower.find(\"none of the registrant's outstanding wotinf stock is held by non-affiliates\")>0:\n",
    "                    mktval = \"none held by non-affiliates\"\n",
    "                elif souptextlower.find(\"registrant has no voting\")>0:\n",
    "                    mktval = \"no boting common equity\"\n",
    "                elif souptextlower.find(\"no established publci trading market for registrant's units\")>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
